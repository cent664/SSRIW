{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**Start** (SET PATH)\n---","metadata":{"id":"wjIO24uflcgu","papermill":{"duration":0.076065,"end_time":"2023-02-04T07:16:24.811761","exception":false,"start_time":"2023-02-04T07:16:24.735696","status":"completed"},"tags":[]}},{"cell_type":"code","source":"experiment = \"SSRIW\"\npath = \"./{}/\".format(experiment)","metadata":{"id":"k2XlB0tgdnSt","papermill":{"duration":0.086992,"end_time":"2023-02-04T07:16:24.971987","exception":false,"start_time":"2023-02-04T07:16:24.884995","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install --upgrade pip\n!pip install vit-keras\n!pip install einops\n\n!pip install scikit-image\n!pip install scikit-learn\n!pip install tensorflow-addons\n!pip install opencv-python\n!pip install opencv-python-headless\n!apt-get update && apt-get install ffmpeg libsm6 libxext6  -y\n!pip install imgaug\n!pip install pydot\n!pip install pydotplus\n!apt -y install graphviz\n!pip install pydot_ng","metadata":{"papermill":{"duration":0.080796,"end_time":"2023-02-04T07:16:25.127129","exception":false,"start_time":"2023-02-04T07:16:25.046333","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nprint(tf.version.VERSION)","metadata":{"papermill":{"duration":5.302318,"end_time":"2023-02-04T07:16:30.506650","exception":false,"start_time":"2023-02-04T07:16:25.204332","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from skimage import data, io, transform, color\nfrom skimage.transform import rescale, resize, downscale_local_mean\nfrom skimage.filters import threshold_otsu\nfrom skimage.util import *\nfrom sklearn.utils import shuffle\n\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nimport tensorflow_addons as tfa\nfrom einops.layers.tensorflow import Rearrange\nfrom mpl_toolkits import axes_grid1\nfrom kaggle_datasets import KaggleDatasets\n\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.activations import *\nfrom tensorflow.keras.models import Model, Sequential\nfrom tensorflow.keras.datasets import cifar10\nimport tensorflow.keras.backend as K\nfrom tensorflow.keras.initializers import glorot_uniform\nfrom tensorflow.keras.utils import *\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n\nimport vit_keras.layers as vit_layers\nfrom vit_keras import vit, utils, visualize\n\nimport imgaug.augmenters as iaa\nimport json\nimport os\nimport random\nimport math\nimport numpy as np\nimport cv2 as cv\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nfrom functools import reduce\n\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning)\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n\nimport logging\nlogger = tf.get_logger()\nlogger.setLevel(logging.ERROR)","metadata":{"papermill":{"duration":2.282936,"end_time":"2023-02-04T07:16:52.881886","exception":false,"start_time":"2023-02-04T07:16:50.598950","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if not os.path.exists(path):\n    os.makedirs(path)","metadata":{"id":"qz_hqBVPfDW6","papermill":{"duration":0.088811,"end_time":"2023-02-04T07:16:53.050163","exception":false,"start_time":"2023-02-04T07:16:52.961352","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Select TPU**\n---","metadata":{"papermill":{"duration":0.078383,"end_time":"2023-02-04T07:16:53.209534","exception":false,"start_time":"2023-02-04T07:16:53.131151","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# detect and init the TPU\ntpu = tf.distribute.cluster_resolver.TPUClusterResolver()\ntf.config.experimental_connect_to_cluster(tpu)\ntf.tpu.experimental.initialize_tpu_system(tpu)\n\n# instantiate a distribution strategy\nstrategy = tf.distribute.TPUStrategy(tpu)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Training Parameters**\n---","metadata":{"papermill":{"duration":0.081105,"end_time":"2023-02-04T07:17:20.763076","exception":false,"start_time":"2023-02-04T07:17:20.681971","status":"completed"},"tags":[]}},{"cell_type":"code","source":"batch_size = 32 * strategy.num_replicas_in_sync\nnum_epochs = 500\nwait = 0\npatience = 15\nnum_classes = 10\ninput_shape = (128, 128, 3)\nwatermark_shape = (8, 8, 1)\nnoise_dim = 512\n\nmlp_dim = 512\nhidden_size = 512\nnum_layers = 4\npatch_size = 16\nnum_heads = 2","metadata":{"papermill":{"duration":0.092327,"end_time":"2023-02-04T07:17:20.937919","exception":false,"start_time":"2023-02-04T07:17:20.845592","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Dataset**\n---","metadata":{"papermill":{"duration":0.081342,"end_time":"2023-02-04T07:17:21.101770","exception":false,"start_time":"2023-02-04T07:17:21.020428","status":"completed"},"tags":[]}},{"cell_type":"code","source":"DATASET_INFO = {}\nAUTO = tf.data.AUTOTUNE","metadata":{"papermill":{"duration":0.105102,"end_time":"2023-02-04T07:17:21.287079","exception":false,"start_time":"2023-02-04T07:17:21.181977","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_dataset(batch_size, dataset_type='TRAIN', batchwise_augment=False):\n    if dataset_type == 'TRAIN':\n        data_dir = '/kaggle/input/imagenetmini-1000/imagenet-mini/train'\n    else:\n        data_dir = '/kaggle/input/imagenetmini-1000/imagenet-mini/val'\n    \n    dataset = tf.keras.utils.image_dataset_from_directory(\n        data_dir,\n        labels=\"inferred\",\n        label_mode=\"int\",\n        class_names=None,\n        color_mode=\"rgb\",\n        batch_size=batch_size,\n        image_size=(128, 128),\n        shuffle=True,\n        seed=None,\n        validation_split=None,\n        subset=None,\n        interpolation=\"bilinear\",\n        follow_links=False,\n        crop_to_aspect_ratio=False\n    )\n    \n    DATASET_INFO[dataset_type] = dataset.cardinality().numpy()*batch_size\n    \n    def watermark(x):\n        w = x[:, :, :, 0]\n        w = tf.math.greater(w, 127)\n        w = tf.where(w, 1, 0)\n        w = tf.expand_dims(w, axis=-1)\n        return w\n    \n    def create_triplets(x, y):\n        # x_n\n        x_n = x\n        \n        # w (also for noised)\n        w = x_n\n        w = tf.image.resize(w, (8, 8))\n        w = watermark(w)\n        w = tf.random.shuffle(w)\n        \n        # w_s\n        w_s = w\n        w_s = tf.random.shuffle(w_s)\n        \n        # x_s and y_s\n        x_s = x\n        y_s = y\n        seed = random.randint(0, 10000)\n        x_s = tf.random.shuffle(x_s, seed=seed)\n        y_s = tf.random.shuffle(y_s, seed=seed)\n        \n        x = tf.cast(x, tf.float32) / 255.0\n        x_n = tf.cast(x_n, tf.float32) / 255.0\n        x_s = tf.cast(x_s, tf.float32) / 255.0\n        w = tf.cast(w, tf.float32)\n        w_s = tf.cast(w_s, tf.float32)\n        y = tf.cast(y, tf.float32)\n        y_s = tf.cast(y_s, tf.float32)\n\n        return x, x_n, x_s, w, w_s, y, y_s\n    \n    dataset = dataset.map(create_triplets, num_parallel_calls=AUTO)\n    dataset = dataset.repeat()\n    dataset = dataset.unbatch()\n    dataset = dataset.batch(batch_size, drop_remainder=True)\n    dataset = dataset.prefetch(AUTO)\n    \n    return dataset","metadata":{"papermill":{"duration":0.099389,"end_time":"2023-02-04T07:17:21.488035","exception":false,"start_time":"2023-02-04T07:17:21.388646","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"PER_REPLICA_BATCH_SIZE = batch_size // strategy.num_replicas_in_sync\n\nif strategy.num_replicas_in_sync > 1:\n    trn_dataset = strategy.distribute_datasets_from_function(\n        lambda _ : get_dataset(PER_REPLICA_BATCH_SIZE, 'TRAIN')\n    )\n    val_dataset = strategy.distribute_datasets_from_function(\n      lambda _ : get_dataset(PER_REPLICA_BATCH_SIZE, 'VAL')\n    )\nelse:\n    trn_dataset = get_dataset(batch_size, 'TRAIN')\n    val_dataset = get_dataset(batch_size, 'VAL')\n    \nprint(f\"train dataset size: {DATASET_INFO['TRAIN']}\")\nprint(f\"val dataset size: {DATASET_INFO['VAL']}\")\n    \ntrn_iterator = iter(trn_dataset)\nval_iterator = iter(val_dataset)","metadata":{"papermill":{"duration":47.025235,"end_time":"2023-02-04T07:18:08.593612","exception":false,"start_time":"2023-02-04T07:17:21.568377","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def normalize_img(temp):\n    return ((temp - np.min(temp)) / (np.max(temp) - np.min(temp)))","metadata":{"papermill":{"duration":0.090521,"end_time":"2023-02-04T07:18:08.941120","exception":false,"start_time":"2023-02-04T07:18:08.850599","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_BER(original, reconstructed):\n    og = np.array(original)\n    rec = np.array(reconstructed)\n    og = np.reshape(og, watermark_shape)\n    rec = np.reshape(rec, watermark_shape)\n    \n    TB = np.prod(og.shape)\n    EB = (og == rec).flatten().tolist().count(False)\n    RB = TB - EB\n    BER = EB*100.0/TB\n    BRR = RB*100.0/TB\n    \n    print('Total bits =', TB)\n    print('Recovered bits =', RB)\n    print('Error bits =', EB)\n    print(f'BRR = {BRR} %')\n    print(f'BER = {BER} %')","metadata":{"papermill":{"duration":0.094559,"end_time":"2023-02-04T07:18:09.117654","exception":false,"start_time":"2023-02-04T07:18:09.023095","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_PSNR(original, reconstructed):\n    og = np.array(original)\n    rec = np.array(reconstructed)\n    og = np.reshape(og, input_shape)\n    rec = np.reshape(rec, input_shape)\n    \n    mse = np.mean((og - rec) ** 2)\n    if(mse == 0):\n        psnr = 100\n    else:\n        max_pixel = 1.0\n        psnr = 20 * math.log10(max_pixel / math.sqrt(mse))\n    \n    print(f'PSNR = {psnr} dB')","metadata":{"papermill":{"duration":0.091768,"end_time":"2023-02-04T07:18:09.292553","exception":false,"start_time":"2023-02-04T07:18:09.200785","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**All models**\n---","metadata":{"papermill":{"duration":0.082155,"end_time":"2023-02-04T07:18:09.805784","exception":false,"start_time":"2023-02-04T07:18:09.723629","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"**Embedder**\n---","metadata":{"papermill":{"duration":0.081868,"end_time":"2023-02-04T07:18:09.971113","exception":false,"start_time":"2023-02-04T07:18:09.889245","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def get_embedder(\n        mlp_dim=mlp_dim,\n        num_heads=num_heads,\n        name='Embedder'):\n    \n    cover_im = Input(shape=input_shape)\n    watermark = Input(shape=watermark_shape)\n    \n    cover_im_ = Rearrange('b (h p1) (w p2) c -> b (h w) (p1 p2 c)', p1=patch_size, p2=patch_size)(cover_im)\n    watermark_ = Rearrange('b (h p1) (w p2) c -> b (h w) (p1 p2 c)', p1=patch_size//16, p2=patch_size//16)(watermark)\n    \n    cover_im_ = vit_layers.AddPositionEmbs(name=\"T_Pos_Embed_c\")(cover_im_)\n    watermark_ = vit_layers.AddPositionEmbs(name=\"T_Pos_Embed_w\")(watermark_)\n    \n    # MHA\n    attention_output_1 = MultiHeadAttention(num_heads=num_heads, key_dim=mlp_dim)(cover_im_, watermark_)\n    attention_output_2 = MultiHeadAttention(num_heads=num_heads, key_dim=mlp_dim)(watermark_, cover_im_)\n    \n    attention_output_1 = Add()([cover_im_, attention_output_1])\n    attention_output_2 = Add()([watermark_, attention_output_2])\n    \n    attention_output = Concatenate()([attention_output_1, attention_output_2])\n    \n    x = Dense(768)(attention_output)\n    h = 128 // patch_size\n    \n    marked_im = Rearrange('b (h w) (p1 p2 c) -> b (h p1) (w p2) c', h=h, w=h, p1=patch_size, p2=patch_size, c=3)(x)\n    \n    model = Model([cover_im, watermark], marked_im, name=name)\n    \n    return model","metadata":{"papermill":{"duration":0.095283,"end_time":"2023-02-04T07:18:10.149639","exception":false,"start_time":"2023-02-04T07:18:10.054356","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Extractor**\n---","metadata":{"papermill":{"duration":0.168056,"end_time":"2023-02-04T07:18:13.147549","exception":false,"start_time":"2023-02-04T07:18:12.979493","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def get_extractor(\n        mlp_dim=mlp_dim,\n        num_heads=num_heads,\n        name='Extractor'):\n    \n    marked_im = Input(shape=input_shape)\n    \n    x = Reshape((8, 8, 768))(marked_im)\n    \n    x = Conv2D(64, 3, padding='same')(x)\n    x = Activation('relu')(x)\n    x = Conv2D(128, 3, padding='same')(x)\n    x = Activation('relu')(x)\n    x = Dropout(0.2)(x)\n    x = Conv2D(256, 3, padding='same')(x)\n    x = Activation('relu')(x)\n    \n    x = Dense(512)(x)\n    \n    x = Conv2D(128, 3, padding='same')(x)\n    x = Activation('relu')(x)\n    x = Dropout(0.2)(x)\n    x = Conv2D(64, 3, padding='same')(x)\n    x = Activation('relu')(x)\n    x = Conv2D(32, 3, padding='same')(x)\n    x = Activation('relu')(x)\n    x = Conv2D(8, 3, padding='same')(x)\n    x = Activation('relu')(x)\n    x = Conv2D(1, 3, padding='same')(x)\n    watermark = Activation('relu')(x)\n    \n    model = Model(marked_im, watermark, name=name)\n    \n    return model","metadata":{"papermill":{"duration":0.126292,"end_time":"2023-02-04T07:18:13.366217","exception":false,"start_time":"2023-02-04T07:18:13.239925","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Encoder**\n---","metadata":{"papermill":{"duration":0.094262,"end_time":"2023-02-04T07:18:14.398159","exception":false,"start_time":"2023-02-04T07:18:14.303897","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def get_encoder(\n        num_layers=num_layers,\n        patch_size=patch_size,\n        hidden_size=hidden_size,\n        mlp_dim=mlp_dim,\n        dropout=.02,\n        num_heads=num_heads,\n        name='Encoder'\n    ):\n    \n    in_channels = 3\n    patch_dim = in_channels * patch_size ** 2\n    h = 128 // patch_size\n    \n    ip = Input(shape=(128, 128, in_channels))\n    \n    y = Rearrange('b (h p1) (w p2) c -> b (h w) (p1 p2 c)', p1=patch_size, p2=patch_size)(ip)\n    \n    y = Dense(hidden_size)(y)\n    y = vit_layers.AddPositionEmbs(name=\"T_Pos_Embed\")(y)\n    \n    for n in range(num_layers):\n        y, _ = vit_layers.TransformerBlock(\n                    num_heads=num_heads,\n                    mlp_dim=mlp_dim,\n                    dropout=dropout,\n                    name=f\"T_Enc_Block_{n}\"\n                )(y)\n    \n    y_ = BatchNormalization()(y)\n    y_ = Flatten()(y_)\n    y_ = Dense(1000)(y_)\n    \n    model = Model(inputs=ip, outputs=[y, y_], name=name)\n    return model","metadata":{"papermill":{"duration":0.10563,"end_time":"2023-02-04T07:18:14.597646","exception":false,"start_time":"2023-02-04T07:18:14.492016","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Decoder**\n---","metadata":{"papermill":{"duration":0.097483,"end_time":"2023-02-04T07:18:16.650668","exception":false,"start_time":"2023-02-04T07:18:16.553185","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def get_decoder(\n        input_shape,\n        num_layers=num_layers,\n        patch_size=patch_size,\n        hidden_size=hidden_size,\n        mlp_dim=mlp_dim,\n        dropout=.02,\n        num_heads=num_heads,\n        name='Decoder'\n    ):\n    \n    in_channels = 3\n    patch_dim = in_channels * patch_size ** 2\n    h = 128 // patch_size\n    \n    ip = Input(shape=input_shape)\n    y = ip\n    \n    for n in range(4):\n        y, _ = vit_layers.TransformerBlock(\n                    num_heads=num_heads,\n                    mlp_dim=mlp_dim,\n                    dropout=dropout,\n                    name=f\"T_Dec_Block_{n}\"\n                )(y)\n    \n    y = LayerNormalization(\n        epsilon=1e-6, name=\"T_LNorm\"\n    )(y)\n    \n    y = Dense(patch_dim)(y)\n    y = Rearrange('b (h w) (p1 p2 c) -> b (h p1) (w p2) c', h=h, w=h, p1=patch_size, p2=patch_size, c=in_channels)(y)\n    \n    model = Model(inputs=ip, outputs=y, name=name)\n    return model","metadata":{"papermill":{"duration":0.112205,"end_time":"2023-02-04T07:18:16.860295","exception":false,"start_time":"2023-02-04T07:18:16.748090","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_size = 128\nencoder = get_encoder()\nchannels = PER_REPLICA_BATCH_SIZE * reduce(lambda x, y: x * y, encoder.output_shape[0][1:]) // (32*32)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Defining all params inside strategy**\n---","metadata":{"papermill":{"duration":0.10101,"end_time":"2023-02-04T07:18:18.638046","exception":false,"start_time":"2023-02-04T07:18:18.537036","status":"completed"},"tags":[]}},{"cell_type":"code","source":"with strategy.scope():\n    margin = 1.0\n    lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n        initial_learning_rate=1e-4,\n        decay_steps=10000,\n        decay_rate=0.9)\n    opt_emb_ext = keras.optimizers.Adam(learning_rate=lr_schedule)\n    opt_enc = keras.optimizers.Adam(learning_rate=1e-4)\n    opt_enc_legacy = keras.optimizers.legacy.Adam(learning_rate=1e-4)\n    opt_ext = keras.optimizers.Adam(learning_rate=1e-4)\n    \n    mse = keras.losses.mean_squared_error\n    @tf.function\n    def mse_loss(z1, z2):\n        return tf.nn.compute_average_loss(keras.losses.mean_squared_error(z1, z2))\n    \n    train_loss_emb = []\n    train_loss_enc = []\n    train_loss_ext = []\n\n    val_loss_emb = []\n    val_loss_enc = []\n    val_loss_ext = []","metadata":{"papermill":{"duration":0.196121,"end_time":"2023-02-04T07:18:18.935064","exception":false,"start_time":"2023-02-04T07:18:18.738943","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with strategy.scope():\n    @tf.function\n    def random_augmenter(x, image_size=128):\n        # Flip\n        if tf.random.uniform([], minval=0, maxval=1) < 0.5: # Default\n#         if tf.random.uniform([], minval=0, maxval=1) < 10.0: # Always\n#         if tf.random.uniform([], minval=0, maxval=1) > 10.0: # Never\n            x = tf.image.flip_left_right(x)\n\n        # Color Jitter\n        if tf.random.uniform([], minval=0, maxval=1) < 0.8: # Default\n#         if tf.random.uniform([], minval=0, maxval=1) < 10.0: # Always\n#         if tf.random.uniform([], minval=0, maxval=1) > 10.0: # Never\n            x = tf.stop_gradient(tf.image.random_brightness(x, 0.4))\n            x = tf.stop_gradient(tf.image.random_contrast(x, 0.5, 2.0))\n            x = tf.stop_gradient(tf.image.random_saturation(x, 0.5, 2.0))\n            x = tf.stop_gradient(tf.image.random_hue(x, 0.25))\n\n        # Guassian Blur\n        if tf.random.uniform([], minval=0, maxval=1) < 0.4: # Default\n#         if tf.random.uniform([], minval=0, maxval=1) < 10.0: # Always\n#         if tf.random.uniform([], minval=0, maxval=1) > 10.0: # Never\n            s = np.random.uniform(1.0, 2.5)\n            x = tfa.image.gaussian_filter2d(image=x, sigma=s)\n\n        # Solarization\n        if tf.random.uniform([], minval=0, maxval=1) < 0.2: # Default\n#         if tf.random.uniform([], minval=0, maxval=1) < 10.0: # Always\n#         if tf.random.uniform([], minval=0, maxval=1) > 10.0: # Never\n            x = tf.where(x < 127/255.0, x, 1.0 - x)\n\n        return x\n\n    augment = tf.keras.Sequential([\n    layers.Lambda(random_augmenter),\n    ])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"og, noised, shuffled, w, w_s, y, y_s = val_iterator.next()\n\ni = 0\n\nog_ = og.values[0]\nnoised_ = noised.values[0]\nshuffled_ = shuffled.values[0]\nw_ = w.values[0]\nw_s_ = w_s.values[0]\ny_ = y.values[0]\ny_s_ = y_s.values[0]\n\nprint(og_[0][0][0][0])\n\nprint(og_.shape, type(og_))\nprint(noised_.shape, type(noised_))\nprint(shuffled_.shape, type(shuffled_))\nprint(w_.shape, type(w_))\nprint(w_s_.shape, type(w_s_))\nprint(y_.shape, type(y_))\nprint(y_s_.shape, type(y_s_))\n\nfig, axs = plt.subplots(1, 5)\n\naxs[0].imshow(og_[i])\naxs[0].set_title(int(y_[i]), fontdict={'fontsize': 80})\naxs[1].imshow(augment(noised_)[i])\naxs[1].set_title(int(y_[i]), fontdict={'fontsize': 80})\naxs[2].imshow(shuffled_[i])\naxs[2].set_title(int(y_s_[i]), fontdict={'fontsize': 80})\naxs[3].imshow(w_[i], cmap='gray')\naxs[4].imshow(w_s_[i], cmap='gray')\n\nprint(augment(noised_)[i].shape)\n\nprint(tf.reduce_sum(og_[i] - augment(noised_)[i]))\n\nfig.set_figheight(10)\nfig.set_figwidth(40)","metadata":{"papermill":{"duration":2.649129,"end_time":"2023-02-04T07:18:22.399699","exception":false,"start_time":"2023-02-04T07:18:19.750570","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# BREAKPOINT_1","metadata":{"papermill":{"duration":0.116314,"end_time":"2023-02-04T07:18:22.626932","exception":false,"start_time":"2023-02-04T07:18:22.510618","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Embedder Model**\n---","metadata":{"papermill":{"duration":0.110142,"end_time":"2023-02-04T07:18:22.846056","exception":false,"start_time":"2023-02-04T07:18:22.735914","status":"completed"},"tags":[]}},{"cell_type":"code","source":"with strategy.scope():\n    embedder = get_embedder()\n#     embedder = get_concat_embedder()\n    \n    # Getting 3 cover images\n    cover_og = keras.Input(shape=input_shape)\n    cover_noised = keras.Input(shape=input_shape)\n    cover_shuffled = keras.Input(shape=input_shape)\n    \n    # Getting 3 watermarks\n    watermark_og = keras.Input(shape=watermark_shape)\n    watermark_noised = keras.Input(shape=watermark_shape)\n    watermark_shuffled = keras.Input(shape=watermark_shape)\n    \n    # Getting marked image\n    marked_og = embedder([cover_og, watermark_og])\n    marked_noised = embedder([cover_noised, watermark_noised])\n    marked_shuffled = embedder([cover_shuffled, watermark_shuffled])\n    \n    emb_train = Model([cover_og, watermark_og], marked_og, name='Embedder_train')","metadata":{"papermill":{"duration":1.378804,"end_time":"2023-02-04T07:18:24.335794","exception":false,"start_time":"2023-02-04T07:18:22.956990","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"emb_train.summary()","metadata":{"papermill":{"duration":0.120868,"end_time":"2023-02-04T07:18:24.565400","exception":false,"start_time":"2023-02-04T07:18:24.444532","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with strategy.scope():\n    extractor = get_extractor()\n    \n    # Getting watermark back\n    watermark_og_ = extractor(marked_og)\n\n    emb_ext_train = Model([cover_og, watermark_og], [marked_og, watermark_og_], name='Embedder_Extractor_train')","metadata":{"papermill":{"duration":1.067556,"end_time":"2023-02-04T07:18:26.314459","exception":false,"start_time":"2023-02-04T07:18:25.246903","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"emb_ext_train.summary()","metadata":{"papermill":{"duration":0.131034,"end_time":"2023-02-04T07:18:26.559544","exception":false,"start_time":"2023-02-04T07:18:26.428510","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Training: Embedder-Extractor Model**\n---","metadata":{"papermill":{"duration":0.127681,"end_time":"2023-02-04T07:18:27.861679","exception":false,"start_time":"2023-02-04T07:18:27.733998","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# BREAKPOINT_2","metadata":{"papermill":{"duration":0.133738,"end_time":"2023-02-04T07:18:28.122365","exception":false,"start_time":"2023-02-04T07:18:27.988627","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"@tf.function\ndef train_step(im_og, im_n, im_s, w, w_s, y, y_s):\n    with tf.GradientTape() as tape:\n        marked_og, watermark_og_ = emb_ext_train([im_og, w], training=True)\n              \n        # Embedder loss\n        embedding_loss = mse_loss(im_og, marked_og)\n        \n        # Watermark extraction loss\n        watermark_loss = mse_loss(w, watermark_og_)\n                \n    grads = tape.gradient([embedding_loss, watermark_loss], emb_ext_train.trainable_variables)    \n    opt_emb_ext.apply_gradients(zip(grads, emb_ext_train.trainable_variables))\n  \n    return embedding_loss, watermark_loss","metadata":{"papermill":{"duration":0.135564,"end_time":"2023-02-04T07:18:28.383241","exception":false,"start_time":"2023-02-04T07:18:28.247677","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"@tf.function\ndef validate_step(im_og, im_n, im_s, w, w_s, y, y_s):  \n    with tf.GradientTape() as tape:\n        marked_og, watermark_og_ = emb_ext_train([im_og, w], training=False)\n              \n        # Embedder loss\n        embedding_loss = mse_loss(im_og, marked_og)\n        \n        # Watermark extraction loss\n        watermark_loss = mse_loss(w, watermark_og_)\n  \n    return embedding_loss, watermark_loss","metadata":{"papermill":{"duration":0.13353,"end_time":"2023-02-04T07:18:28.641757","exception":false,"start_time":"2023-02-04T07:18:28.508227","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_emb = 1000000000\nbest_ext = 1000000000\nwait = 0\ntrain_loss_emb = []\ntrain_loss_ext = []\nval_loss_emb = []\nval_loss_ext = []\n    \nfor epoch in range(num_epochs):\n    \n    batch_count = 0\n    emb_sum = 0\n    wat_sum = 0\n    for i in range(DATASET_INFO['TRAIN']//PER_REPLICA_BATCH_SIZE):\n        batch_count += 1\n        \n        print('\\rEpoch [%d/%d] Batch: %d%s' % (epoch + 1, num_epochs, batch_count, '.' * (batch_count % 10)), end='')\n        emb_loss, wat_loss = strategy.run(train_step, args=(next(trn_iterator)))\n        emb_sum += tf.math.reduce_sum(emb_loss.values)\n        wat_sum += tf.math.reduce_sum(wat_loss.values)\n    train_loss_emb.append(emb_sum/batch_size)\n    train_loss_ext.append(wat_sum/batch_size)\n    \n    emb_sum = 0\n    wat_sum = 0\n    for i in range(DATASET_INFO['VAL']//PER_REPLICA_BATCH_SIZE):\n        emb_loss, wat_loss = strategy.run(validate_step, args=(next(val_iterator)))\n        emb_sum += tf.math.reduce_sum(emb_loss.values)\n        wat_sum += tf.math.reduce_sum(wat_loss.values)\n    val_loss_emb.append(emb_sum/batch_size)\n    val_loss_ext.append(wat_sum/batch_size)\n    \n    print()\n    print('Training loss(emb): {} - Validation loss(emb): {}'.format(train_loss_emb[epoch], val_loss_emb[epoch]))\n    print('Training loss(ext): {} - Validation loss(ext): {}'.format(train_loss_ext[epoch], val_loss_ext[epoch]))\n    \n    # Early Stopping\n    wait += 1\n    if val_loss_emb[epoch] < best_emb and val_loss_ext[epoch] < best_ext:\n        best_emb = val_loss_emb[epoch]\n        best_ext = val_loss_ext[epoch]\n        wait = 0\n        print(f'Best Embedder loss: {best_emb}, Best Extractor loss: {best_ext}')\n        emb_ext_train.save_weights(path + 'emb_ext_{}.h5'.format(experiment))\n    else:\n        print('Not saved!')\n    if wait >= patience:\n        print(f'Training stagnated for {patience} epochs')\n        break","metadata":{"papermill":{"duration":0.134439,"end_time":"2023-02-04T07:18:28.901530","exception":false,"start_time":"2023-02-04T07:18:28.767091","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plotting loss\nfig, ax = plt.subplots(1, 1, figsize=(20, 20))\n\nax.plot(train_loss_emb)\nax.plot(train_loss_ext)\n\nax.plot(val_loss_emb)\nax.plot(val_loss_ext)\n\nax.set_title('Embedder Extractor loss')\nax.set(xlabel='Epoch', ylabel='Loss')\nax.grid()\nax.legend(['Train_emb', 'Train_ext', 'Validation_emb', 'Validation_ext'], loc='upper right')\n\nfig.savefig(path + 'Embedder_Extractor - Training.png')","metadata":{"papermill":{"duration":0.133936,"end_time":"2023-02-04T07:18:29.162606","exception":false,"start_time":"2023-02-04T07:18:29.028670","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"emb_ext_train.load_weights(path + 'emb_ext_{}.h5'.format(experiment))","metadata":{"papermill":{"duration":0.959116,"end_time":"2023-02-04T07:18:30.248513","exception":false,"start_time":"2023-02-04T07:18:29.289397","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot():\n    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(40, 40))\n    \n    noised_, w_ = emb_ext_train.predict([noised.values[0], w.values[0]])\n\n    ax1.imshow(noised.values[0][0])\n    ax2.imshow(w.values[0][0], cmap='gray')\n\n    w_ = extractor.predict(noised_)\n    ax3.imshow(noised_[0])\n    ax4.imshow(cv.threshold(normalize_img(w_[0]), 0.5, 1.0, cv.THRESH_BINARY)[1], cmap='gray')\n    \n    print('===================================\\nCover and marked:')\n    get_PSNR(noised.values[0][0], noised_[0])\n    \n    print('===================================\\nWatermark:')\n    get_BER(w.values[0][0], cv.threshold(normalize_img(w_[0]), 0.5, 1.0, cv.THRESH_BINARY)[1])\n\n    fig.savefig(path + 'Embedder_Extractor - Results.png')\n    \n    ax1.set_xticklabels([])\n    ax1.set_yticklabels([])\n    ax2.set_xticklabels([])\n    ax2.set_yticklabels([])\n    ax3.set_xticklabels([])\n    ax3.set_yticklabels([])\n    ax4.set_xticklabels([])\n    ax4.set_yticklabels([])\n    plt.show()\n    \n    return noised.values[0][0], noised_[0]\n    \ntemp_c, temp_m = plot()","metadata":{"papermill":{"duration":5.327422,"end_time":"2023-02-04T07:18:35.705126","exception":false,"start_time":"2023-02-04T07:18:30.377704","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Watermark Location**\n---","metadata":{}},{"cell_type":"code","source":"fig, ((ax1, ax2, ax3), (ax4, ax5, ax6)) = plt.subplots(2, 3, figsize=(30, 20))\n\ndiff = (temp_c - temp_m)*20.0\n\nax1.imshow(temp_c)\nax2.imshow(temp_m)\nax3.imshow(diff, cmap='gray')\nax4.imshow(diff[:, :, 0], cmap='gray')\nax5.imshow(diff[:, :, 1], cmap='gray')\nax6.imshow(diff[:, :, 2], cmap='gray')\n\nax1.set_xticklabels([])\nax1.set_yticklabels([])\nax2.set_xticklabels([])\nax2.set_yticklabels([])\nax3.set_xticklabels([])\nax3.set_yticklabels([])\nax4.set_xticklabels([])\nax4.set_yticklabels([])\nax5.set_xticklabels([])\nax5.set_yticklabels([])\nax6.set_xticklabels([])\nax6.set_yticklabels([])\n\nprint(np.min(temp_c), np.max(temp_c))\nprint(np.min(temp_m), np.max(temp_m))\nprint(np.min(diff), np.max(diff))\n\nplt.savefig(path + 'Watermark location.png')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# BREAKPOINT_3","metadata":{"papermill":{"duration":0.142893,"end_time":"2023-02-04T07:18:38.206892","exception":false,"start_time":"2023-02-04T07:18:38.063999","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Encoder Model**\n---","metadata":{"papermill":{"duration":0.135294,"end_time":"2023-02-04T07:18:39.336793","exception":false,"start_time":"2023-02-04T07:18:39.201499","status":"completed"},"tags":[]}},{"cell_type":"code","source":"with strategy.scope():\n    encoder = get_encoder()\n    marked_noised_ = augment(marked_noised)\n    \n    # Getting 3 latent domains\n    code_og, label_og = encoder(marked_og)\n    code_noised, label_noised = encoder(marked_noised_)\n    code_shuffled, label_shuffled = encoder(marked_shuffled)","metadata":{"papermill":{"duration":4.008229,"end_time":"2023-02-04T07:18:43.480145","exception":false,"start_time":"2023-02-04T07:18:39.471916","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"emb_ext_train.trainable = False","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with strategy.scope():\n    # Training model\n    enc_train = Model([cover_og, cover_noised, cover_shuffled,\n                 watermark_og, watermark_noised, watermark_shuffled],\n                [code_og, code_noised, code_shuffled, label_og, label_noised, label_shuffled],\n                name='Encoder_train')","metadata":{"papermill":{"duration":0.18811,"end_time":"2023-02-04T07:18:44.079652","exception":false,"start_time":"2023-02-04T07:18:43.891542","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"enc_train.summary()","metadata":{"papermill":{"duration":0.179555,"end_time":"2023-02-04T07:18:44.424366","exception":false,"start_time":"2023-02-04T07:18:44.244811","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Training: Encoder Model**\n---","metadata":{"papermill":{"duration":0.14822,"end_time":"2023-02-04T07:18:45.929555","exception":false,"start_time":"2023-02-04T07:18:45.781335","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# BREAKPOINT_4","metadata":{"papermill":{"duration":0.15325,"end_time":"2023-02-04T07:18:46.230230","exception":false,"start_time":"2023-02-04T07:18:46.076980","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"@tf.function\ndef train_step(im_og, im_n, im_s, w, w_s, y, y_s):\n    with tf.GradientTape() as tape:\n        code_og, code_noised, code_shuffled, label_og, label_noised, label_shuffled = enc_train([im_og, im_n, im_s, w, w, w_s], training=True)\n        \n        # Encoder triplet loss\n        positive_anchor_loss = mse(code_og, code_noised)\n        negative_anchor_loss = mse(code_og, code_shuffled)\n        encoding_loss = tf.maximum(positive_anchor_loss - negative_anchor_loss + margin, 0.0)\n    \n    enc_grads = tape.gradient(encoding_loss, enc_train.trainable_variables)\n    opt_enc.apply_gradients(zip(enc_grads, enc_train.trainable_variables))\n  \n    return encoding_loss","metadata":{"papermill":{"duration":0.156188,"end_time":"2023-02-04T07:18:46.532049","exception":false,"start_time":"2023-02-04T07:18:46.375861","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"@tf.function\ndef validate_step(im_og, im_n, im_s, w, w_s, y, y_s):\n    with tf.GradientTape() as tape:\n        code_og, code_noised, code_shuffled, label_og, label_noised, label_shuffled = enc_train([im_og, im_n, im_s, w, w, w_s], training=False)\n        \n        # Encoder triplet loss\n        positive_anchor_loss = mse(code_og, code_noised)\n        negative_anchor_loss = mse(code_og, code_shuffled)\n        encoding_loss = tf.maximum(positive_anchor_loss - negative_anchor_loss + margin, 0.0)\n  \n    return encoding_loss","metadata":{"papermill":{"duration":0.154348,"end_time":"2023-02-04T07:18:46.831046","exception":false,"start_time":"2023-02-04T07:18:46.676698","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best = 1000000000\nwait = 0\ntrain_loss_enc = []\nval_loss_enc = []\n    \nfor epoch in range(num_epochs):\n    \n    batch_count = 0\n    enc_sum = 0\n    for i in range(DATASET_INFO['TRAIN']//PER_REPLICA_BATCH_SIZE):\n        batch_count += 1\n        \n        print('\\rEpoch [%d/%d] Batch: %d%s' % (epoch + 1, num_epochs, batch_count, '.' * (batch_count % 10)), end='')\n        enc_loss = strategy.run(train_step, args=(next(trn_iterator)))\n        enc_sum += tf.math.reduce_sum(enc_loss.values)\n    train_loss_enc.append(enc_sum/batch_size)\n    \n    enc_sum = 0\n    for i in range(DATASET_INFO['VAL']//PER_REPLICA_BATCH_SIZE):\n        enc_loss = strategy.run(validate_step, args=(next(val_iterator)))\n        enc_sum += tf.math.reduce_sum(enc_loss.values)\n    val_loss_enc.append(enc_sum/batch_size)\n    \n    print()\n    print('Training loss(enc): {} - Validation loss(enc): {}'.format(train_loss_enc[epoch], val_loss_enc[epoch]))\n    \n    # Early Stopping\n    wait += 1\n    if np.mean(val_loss_enc[epoch]) < best:\n        best = np.mean(val_loss_enc[epoch])\n        wait = 0\n        print(f'Best Encoding loss: {best}')\n        enc_train.save_weights(path + 'enc_{}.h5'.format(experiment))\n    else:\n        print('Not saved!')\n    if wait >= patience:\n        break","metadata":{"papermill":{"duration":0.156153,"end_time":"2023-02-04T07:18:47.132654","exception":false,"start_time":"2023-02-04T07:18:46.976501","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plotting loss\nfig, ax = plt.subplots(1, 1, figsize=(20, 20))\n\nax.plot(train_loss_enc)\n\nax.plot(val_loss_enc)\n\nax.set_title('Encoder loss')\nax.set(xlabel='Epoch', ylabel='Encoder loss')\nax.grid()\nax.legend(['Train_enc', 'Validation_enc'], loc='upper right')\n\nfig.savefig(path + 'Encoder - Training.png'.format(experiment))","metadata":{"papermill":{"duration":0.690255,"end_time":"2023-02-04T07:18:47.968956","exception":false,"start_time":"2023-02-04T07:18:47.278701","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"enc_train.load_weights(path + 'enc_{}.h5'.format(experiment))","metadata":{"papermill":{"duration":1.698132,"end_time":"2023-02-04T07:18:49.814647","exception":false,"start_time":"2023-02-04T07:18:48.116515","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot():\n    fig, ((ax1, ax2, ax3), (ax4, ax5, ax6), (ax7, ax8, ax9), (ax10, ax11, ax12)) = plt.subplots(4, 3, figsize=(60, 80))\n    \n    ax1.imshow(og.values[0][0])\n    ax2.imshow(noised.values[0][0])\n    ax3.imshow(shuffled.values[0][0])\n\n    ax4.imshow(w.values[0][0], cmap='gray')\n    ax5.imshow(w.values[0][0], cmap='gray')\n    ax6.imshow(w_s.values[0][0], cmap='gray')\n\n    og_, og_w_ = emb_ext_train.predict([og.values[0], w.values[0]])\n    noised_, noised_w_ = emb_ext_train.predict([noised.values[0], w.values[0]])\n    shuffled_, shuffled_w_ = emb_ext_train.predict([shuffled.values[0], w_s.values[0]])\n\n    noised_marked = augment(noised_)\n    \n    ax7.imshow(og_[0])\n    ax8.imshow(noised_marked[0])\n    ax9.imshow(shuffled_[0])\n    \n    og_c, og_label = encoder.predict(og_)\n    noised_c, noised_label = encoder.predict(noised_marked)\n    shuffled_c, shuffled_label = encoder.predict(shuffled_)\n    \n    ax10.imshow(np.reshape(og_c, (32, 32, channels))[:, :, 0])\n    ax11.imshow(np.reshape(noised_c, (32, 32, channels))[:, :, 0])\n    ax12.imshow(np.reshape(shuffled_c, (32, 32, channels))[:, :, 0])\n\n    fig.savefig(path + 'Encoder - Results.png')\n\n    print(\"Og_c - Noised_c = \", tf.reduce_mean(og_c[0] - noised_c[0]))\n    print(\"Og_c - Shuffled_c = \", tf.reduce_mean(og_c[0] - shuffled_c[0]))\n    print(\"Noised_c - Shuffled_c = \", tf.reduce_mean(noised_c[0] - shuffled_c[0]))\n    \n    plt.show()\n\nplot()","metadata":{"papermill":{"duration":11.126072,"end_time":"2023-02-04T07:19:01.087891","exception":false,"start_time":"2023-02-04T07:18:49.961819","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Decoder Model**\n---","metadata":{"papermill":{"duration":0.159788,"end_time":"2023-02-04T07:19:01.410640","exception":false,"start_time":"2023-02-04T07:19:01.250852","status":"completed"},"tags":[]}},{"cell_type":"code","source":"with strategy.scope():\n    decoder = get_decoder(encoder.output_shape[0][1:])\n    \n    # Getting 3 watermarks and cover images back\n    marked_og_ = decoder(code_og)\n    marked_noised__ = decoder(code_noised)\n    marked_shuffled_ = decoder(code_shuffled)","metadata":{"papermill":{"duration":3.895902,"end_time":"2023-02-04T07:19:05.466438","exception":false,"start_time":"2023-02-04T07:19:01.570536","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# enc_train.trainable = False","metadata":{"papermill":{"duration":0.166997,"end_time":"2023-02-04T07:19:05.793989","exception":false,"start_time":"2023-02-04T07:19:05.626992","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with strategy.scope():\n    # Training model\n    ae_train = Model([cover_og, cover_noised, cover_shuffled,\n                watermark_og, watermark_noised, watermark_shuffled],\n               [marked_og, marked_noised, marked_shuffled,\n                marked_og_, marked_noised__, marked_shuffled_],\n               name='AE_train')","metadata":{"papermill":{"duration":0.193667,"end_time":"2023-02-04T07:19:06.149018","exception":false,"start_time":"2023-02-04T07:19:05.955351","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ae_train.summary()","metadata":{"papermill":{"duration":0.188059,"end_time":"2023-02-04T07:19:06.496538","exception":false,"start_time":"2023-02-04T07:19:06.308479","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# BREAKPOINT_5","metadata":{"papermill":{"duration":0.183706,"end_time":"2023-02-04T07:19:08.811930","exception":false,"start_time":"2023-02-04T07:19:08.628224","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Extractor Model**\n---","metadata":{"papermill":{"duration":0.199858,"end_time":"2023-02-04T07:19:25.416272","exception":false,"start_time":"2023-02-04T07:19:25.216414","status":"completed"},"tags":[]}},{"cell_type":"code","source":"with strategy.scope():\n    extractor = get_extractor()\n    \n    # Getting 3 watermarks and cover images back\n    watermark_og_ = extractor(marked_og_)\n    watermark_noised_ = extractor(marked_noised__)\n    watermark_shuffled_ = extractor(marked_shuffled_)","metadata":{"papermill":{"duration":0.776845,"end_time":"2023-02-04T07:19:26.395717","exception":false,"start_time":"2023-02-04T07:19:25.618872","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# decoder.trainable = False\n# encoder.trainable = False","metadata":{"papermill":{"duration":0.21052,"end_time":"2023-02-04T07:19:26.812310","exception":false,"start_time":"2023-02-04T07:19:26.601790","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"extractor.trainable=True","metadata":{"papermill":{"duration":0.209357,"end_time":"2023-02-04T07:19:27.221489","exception":false,"start_time":"2023-02-04T07:19:27.012132","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with strategy.scope():\n    # Training model\n    ext_train = Model([cover_og, cover_noised, cover_shuffled,\n                       watermark_og, watermark_noised, watermark_shuffled],\n                      [watermark_og_, watermark_noised_, watermark_shuffled_],\n                      name='Extractor_train')","metadata":{"papermill":{"duration":0.236826,"end_time":"2023-02-04T07:19:27.659637","exception":false,"start_time":"2023-02-04T07:19:27.422811","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ext_train.summary()","metadata":{"papermill":{"duration":0.225183,"end_time":"2023-02-04T07:19:28.082517","exception":false,"start_time":"2023-02-04T07:19:27.857334","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Training: Extractor Model**\n---","metadata":{"papermill":{"duration":0.22599,"end_time":"2023-02-04T07:19:31.026791","exception":false,"start_time":"2023-02-04T07:19:30.800801","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# BREAKPOINT_6","metadata":{"papermill":{"duration":0.230316,"end_time":"2023-02-04T07:19:31.480248","exception":false,"start_time":"2023-02-04T07:19:31.249932","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"@tf.function\ndef train_step(im_og, im_n, im_s, w, w_s, y, y_s):\n    with tf.GradientTape() as tape:\n        watermark_og_, watermark_noised_, watermark_shuffled_ = ext_train([im_og, im_n, im_s, w, w, w_s], training=True)\n              \n        # Watermark extraction loss\n        extraction_loss = mse_loss(w, watermark_og_) + mse_loss(w, watermark_noised_) + mse_loss(w_s, watermark_shuffled_)\n                \n    grads = tape.gradient(extraction_loss, ext_train.trainable_variables)\n    opt_ext.apply_gradients(zip(grads, ext_train.trainable_variables))\n  \n    return extraction_loss","metadata":{"papermill":{"duration":0.229158,"end_time":"2023-02-04T07:19:31.927522","exception":false,"start_time":"2023-02-04T07:19:31.698364","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"@tf.function\ndef validate_step(im_og, im_n, im_s, w, w_s, y, y_s):\n    with tf.GradientTape() as tape:\n        watermark_og_, watermark_noised_, watermark_shuffled_ = ext_train([im_og, im_n, im_s, w, w, w_s], training=False)\n              \n        # Watermark extraction loss\n        extraction_loss = mse_loss(w, watermark_og_) + mse_loss(w, watermark_noised_) + mse_loss(w_s, watermark_shuffled_)\n  \n    return extraction_loss","metadata":{"papermill":{"duration":0.229539,"end_time":"2023-02-04T07:19:32.375496","exception":false,"start_time":"2023-02-04T07:19:32.145957","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_ext = 1000000000\nwait = 0\ntrain_loss_ext = []\nval_loss_ext = []\n    \nfor epoch in range(num_epochs):\n    \n    batch_count = 0\n    ext_sum = 0\n    for i in range(DATASET_INFO['TRAIN']//PER_REPLICA_BATCH_SIZE):\n        batch_count += 1\n        \n        print('\\rEpoch [%d/%d] Batch: %d%s' % (epoch + 1, num_epochs, batch_count, '.' * (batch_count % 10)), end='')\n        ext_loss = strategy.run(train_step, args=(next(trn_iterator)))\n        ext_sum += tf.math.reduce_sum(ext_loss.values)\n    train_loss_ext.append(ext_sum/batch_size)\n    \n    ext_sum = 0\n    for i in range(DATASET_INFO['VAL']//PER_REPLICA_BATCH_SIZE):\n        ext_loss = strategy.run(validate_step, args=(next(val_iterator)))\n        ext_sum += tf.math.reduce_sum(ext_loss.values)\n    val_loss_ext.append(ext_sum/batch_size)\n    \n    print()\n    print('Training loss(ext): {} - Validation loss(ext): {}'.format(train_loss_ext[epoch], val_loss_ext[epoch]))\n    \n    # Early Stopping\n    wait += 1\n    if val_loss_ext[epoch] < best_ext:\n        best_ext = val_loss_ext[epoch]\n        wait = 0\n        print(f'Best Extractor loss: {best_ext}')\n        ext_train.save_weights(path + 'ext_{}.h5'.format(experiment))\n    else:\n        print('Not saved!')\n    if wait >= patience:\n        break","metadata":{"papermill":{"duration":25036.041799,"end_time":"2023-02-04T14:16:48.633885","exception":false,"start_time":"2023-02-04T07:19:32.592086","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plotting loss\nfig, ax = plt.subplots(1, 1, figsize=(20, 20))\n\nax.plot(train_loss_ext)\nax.plot(val_loss_ext)\n\nax.set_title('Extractor loss')\nax.set(xlabel='Epoch', ylabel='Extractor loss')\nax.grid()\nax.legend(['Train', 'Validation'], loc='upper right')\n\nfig.savefig(path + 'Extractor - Training.png'.format(experiment))","metadata":{"papermill":{"duration":28.804402,"end_time":"2023-02-04T14:17:43.794819","exception":false,"start_time":"2023-02-04T14:17:14.990417","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ext_train.load_weights(path + 'ext_{}.h5'.format(experiment))","metadata":{"papermill":{"duration":28.634646,"end_time":"2023-02-04T14:18:39.109097","exception":false,"start_time":"2023-02-04T14:18:10.474451","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot():\n    fig, axs = plt.subplots(3, 5, figsize=(100, 60))\n\n    axs[0, 0].imshow(og.values[0][0])\n    axs[1, 0].imshow(noised.values[0][0])\n    axs[2, 0].imshow(shuffled.values[0][0])\n\n    axs[0, 1].imshow(w.values[0][0], cmap='gray')\n    axs[1, 1].imshow(w.values[0][0], cmap='gray')\n    axs[2, 1].imshow(w_s.values[0][0], cmap='gray')\n\n    og_, og_w_ = emb_ext_train.predict([og.values[0], w.values[0]])\n    noised_, noised_w_ = emb_ext_train.predict([noised.values[0], w.values[0]])\n    shuffled_, shuffled_w_ = emb_ext_train.predict([shuffled.values[0], w_s.values[0]])\n\n    noised_marked = augment(noised_)\n    axs[0, 2].imshow(og_[0])\n    axs[1, 2].imshow(noised_marked[0])\n    axs[2, 2].imshow(shuffled_[0])\n    \n    og_c, og_label = encoder.predict(og_)\n    noised_c, noised_label = encoder.predict(noised_marked)\n    shuffled_c, shuffled_label = encoder.predict(shuffled_)\n    \n    axs[0, 3].imshow(np.reshape(og_c, (32, 32, channels))[:, :, 0])\n    axs[1, 3].imshow(np.reshape(noised_c, (32, 32, channels))[:, :, 0])\n    axs[2, 3].imshow(np.reshape(shuffled_c, (32, 32, channels))[:, :, 0])\n    \n    marked_og_ = decoder.predict(og_c)\n    marked_noised_ = decoder.predict(noised_c)\n    marked_shuffled_ = decoder.predict(shuffled_c)\n    \n    og_w_ = extractor.predict(marked_og_)\n    noised_w_ = extractor.predict(marked_noised_)\n    shuffled_w_ = extractor.predict(marked_shuffled_)\n    \n    axs[0, 4].imshow(cv.threshold(normalize_img(og_w_[0]), 0.5, 1.0, cv.THRESH_BINARY)[1], cmap='gray')\n    axs[1, 4].imshow(cv.threshold(normalize_img(noised_w_[0]), 0.5, 1.0, cv.THRESH_BINARY)[1], cmap='gray')\n    axs[2, 4].imshow(cv.threshold(normalize_img(shuffled_w_[0]), 0.5, 1.0, cv.THRESH_BINARY)[1], cmap='gray')\n    \n    axs = axs.flatten()\n    for ax in axs:\n        ax.set_xticks([])\n        ax.set_yticks([])\n\n    fig.savefig(path + 'Functionality - Results.png')\n\n    print(\"===================================\")\n    print(\"Og_c - Noised_c = \", tf.reduce_mean(og_c[0] - noised_c[0]))\n    print(\"Og_c - Shuffled_c = \", tf.reduce_mean(og_c[0] - shuffled_c[0]))\n    \n    print('===================================\\nCover and marked:')\n    print('----------\\nOg - Og_:')\n    get_PSNR(og.values[0][0], og_[0])\n    print('----------\\nNoised - Noised_:')\n    get_PSNR(noised.values[0][0], noised_marked[0])\n    print('----------\\nShuffled - Shuffled_:')\n    get_PSNR(shuffled.values[0][0], shuffled_[0])\n        \n    print('===================================\\nWatermark:')\n    print('----------\\nOg:')\n    get_BER(w.values[0][0], cv.threshold(normalize_img(og_w_[0]), 0.5, 1.0, cv.THRESH_BINARY)[1])\n    print('----------\\nNoised:')\n    get_BER(w.values[0][0], cv.threshold(normalize_img(noised_w_[0]), 0.5, 1.0, cv.THRESH_BINARY)[1])\n    print('----------\\nShuffled:')\n    get_BER(w_s.values[0][0], cv.threshold(normalize_img(shuffled_w_[0]), 0.5, 1.0, cv.THRESH_BINARY)[1])\n    \n    plt.show()\n    \nplot()","metadata":{"papermill":{"duration":40.174366,"end_time":"2023-02-04T14:19:45.829306","exception":false,"start_time":"2023-02-04T14:19:05.654940","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]}]}